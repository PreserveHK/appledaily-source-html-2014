<html><header><meta charset="utf-8"><title>人工智能軍備自選目標惹爭議</title></header><body><h1>人工智能軍備<br>自選目標惹爭議</h1><p>人工智能的可靠性一直為人詬病，相關軍事應用更引起道德爭議，有人擔心若任由攻擊性武器自行挑選目標，將更容易挑起戰爭。<br>武器一旦以人工智能操作，挑選哪個目標及是否作出攻擊就全交由電腦決定，為免計算有誤而掀起不必要戰事，美國國防部2012年曾作出指引，要求自動化武器必須「容許指揮官及操作員，在使用武力上行使一定程度的判斷」。</p><p>攻擊重任應交人手操控</p><p>不過聯合國特別報告員海恩斯（Christof Heyns）認為，即使武器有後備系統，但人手往往難以追上電腦，不會來得及反應作出更正，要確保萬全，始終應該將攻擊重任交由人手操控。瑞士日內瓦今天將召開國際會議，研究自動化武器應否受《特定常規武器公約》監管。<br>支持者卻認為智能武器有其可取之處，例如英國「硫磺」導彈三年前試過在利比亞及時摧毀多輛正在轟炸平民的坦克，同一時間還擊中其餘最少八個目標，準確度與效率都是人手操作難以媲美。軍事專家沙爾（Paul Scharre）指，「更佳更聰明的武器對抑制肆意屠殺確實有幫助」。<br>美國《紐約時報》</p></body></html>