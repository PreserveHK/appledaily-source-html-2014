<html><header><meta charset="utf-8"><title>What we are reading：超級智能：人類遺作或救星？ - TC</title></header><body><h1>What we are reading：<br>超級智能：人類遺作或救星？ - TC</h1><p>「人工智能的全面發展將會導致人類滅絕。」霍金語出驚人並非初次。《Transcendence》上映時他曾聯同三位科學家發表文章，認為「人工智能可能是人類史上最重要的創造，但恐怕是遺作，除非我們學會怎樣避險。」太空飛行創業家Elon Musk月前亦指出，「人工智能是人類最大的生存威脅」。今年新書《超級智能（Superintelligence）》的主題，廣受關注。<br>人類正進入科技以指數式倍增的「第二機械時代」，生存和福祉正面對空前的潛在危險。《超級智能》作者Nick Bostrom在牛津大學創立的「人類未來學院」專事這方面的研究，他們認為目前核子武器戰爭仍是人類滅絕的最大隱憂，但生物和納米科技將會很快取而代之。這些都不難明白，但我們所知的所謂人工智能，只是人寫的電腦程式，有甚麼可怕？<br>可怕在沒有人知道它將會怎樣演化，會不會突然如霍金所說，「會自行起動，重新以不斷增加的速度自我完善設計」，成為超級智能。以機械為載體的智能，其運算處理比神經元網絡快以百萬、億萬倍計，容量沒有人類母體產道對大腦的限制。超級智能勝過人類，將會遠遠超過人和鼠鳥之間的差異。<br>《Transcendence》電影中，人腦上載互聯網後以光速及電腦頻率演化，是《超級智能》所描述的進路之一（讀者亦可閱其短文《Five ways the superintelligence revolution might happen》）。電影中人類大難不死，除了太樂觀，智能也不超級。真正超級的智能，會準備好才發難，人類沒機會扺抗。控制人工智能一個想當然的方法是「關電掣」，但沒有智能手機不能存活的現代人都知，只要「智能」帶來足夠的好處，就會有人守護它。<br>Nick Bostrom認為，首先要脫離擬人化及萬物之靈的思維模式，才能開始想像超級智能的能力。未來的超級智能很可能由機械智能開始演化，不受生物物理局限，臨界點過後的飛躍可能在秒間發生，人類不會有時間準備。機械智能沒有經過生物式的社會演化，意志和價值難以預料。它可能只是一個專注於生產的萬字夾機器，沒有意圖傷害人類。但各式各樣的超級智能演化過程中，必然會形成一些共同的功能價值，例如保護目標完整性、提升認知能力、完善技術、攫取資源。單是最後一項，就足以驅使「萬字夾機器」毀滅人類。<br>「在智能爆發的可能性當前，人類就像玩炸彈的小孩……超級智能是我們現在及將來都不會有充份準備的挑戰……能理性地一起放下這危險品的機會幾乎是零，總有儍人會按掣引爆，只因想看看結果。」Bostrom的結論很悲觀。這位曾修讀理論物理的哲學家深明科技會帶來人類滅絕的威脅，開展研究之前，必須分辨各命題的緩急先後。<br>專欄作家陶傑談論霍金對人工智能的擔憂時，有「哲學也沒有甚麼新花樣出來了」之說，希望他一讀《超級智能》，必有當頭捧喝之效。在人類擁有前所未有能力的新世界，科學更需要人文和哲學。<br><br>TC</p></body></html>